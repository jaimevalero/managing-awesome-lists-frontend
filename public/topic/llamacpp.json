{"category_type":"topic","category_name":"llamacpp","repos_data":[{"full_name":"menloresearch/jan","description":"Jan is an open source alternative to ChatGPT that runs 100% offline on your computer.","topics":["llamacpp","localai","self-hosted","gpt","tauri","chatgpt","llm","open-source"],"created_at":"2023-08-17T02:17:10Z","pushed_at":"2026-01-19T06:44:26Z","stargazers_count":40096,"language":"Makefile"},{"full_name":"serge-chat/serge","description":"A web interface for chatting with Alpaca through llama.cpp. Fully dockerized, with an easy to use API.","topics":["llama","alpaca","docker","fastapi","llamacpp","python","web","svelte","sveltekit","tailwindcss"],"created_at":"2023-03-19T08:33:29Z","pushed_at":"2025-11-21T08:07:36Z","stargazers_count":5751,"language":"Python"},{"full_name":"Michael-A-Kuykendall/shimmy","description":"⚡ Python-free Rust inference server — OpenAI-API compatible. GGUF + SafeTensors, hot model swap, auto-discovery, single binary. FREE now, FREE forever.","topics":["llama","llamacpp","llm-inference","ollama-api","command-line-tool","gguf","inference-server","local-ai","lora","machine-learning"],"created_at":"2025-08-28T22:55:46Z","pushed_at":"2026-01-16T23:01:22Z","stargazers_count":3538,"language":"Rust"},{"full_name":"ngxson/wllama","description":"WebAssembly binding for llama.cpp - Enabling on-browser LLM inference","topics":["llama","llamacpp","llm","wasm","webassembly"],"created_at":"2024-03-13T23:18:27Z","pushed_at":"2025-12-17T09:56:21Z","stargazers_count":981,"language":"CMake"},{"full_name":"shu223/iOS-GenAI-Sampler","description":"A collection of Generative AI examples on iOS.","topics":["genai","generative-ai","ios","llamacpp","locall","metal","openai","openai-api","swift"],"created_at":"2024-05-29T22:02:06Z","pushed_at":"2025-10-28T17:12:33Z","stargazers_count":148,"language":"Swift"}],"frecuent_topics":{"llamacpp":5,"llama":3,"llm":2,"localai":1,"self-hosted":1}}