{"category_type":"topic","category_name":"blackwell","repos_data":[{"full_name":"NVIDIA/TensorRT-LLM","description":"TensorRT LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and supports state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT LLM also contains components to create Python and C++ runtimes that orchestrate the inference execution in a performant way.","topics":["blackwell","cuda","moe","pytorch","llm-serving"],"created_at":"2023-08-16T17:14:27Z","pushed_at":"2025-12-19T14:14:27Z","stargazers_count":12425,"language":"Python"}],"frecuent_topics":{"blackwell":1,"cuda":1,"moe":1,"pytorch":1,"llm-serving":1}}