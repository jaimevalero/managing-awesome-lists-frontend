{"category_type":"topic","category_name":"prompts","repos_data":[{"full_name":"typpo/promptfoo","description":"Test your prompts, models, RAGs. Evaluate and compare LLM outputs, catch regressions, and improve prompt quality. LLM evals for OpenAI/Azure GPT, Anthropic Claude, VertexAI Gemini, Ollama, Local & private models like Mistral/Mixtral/Llama with CI/CD","topics":["llm","prompt-engineering","prompts","llmops","prompt-testing","testing","rag","evaluation","evaluation-framework","llm-eval"],"created_at":"2023-04-28T15:48:49Z","pushed_at":"2024-01-28T03:19:41Z","stargazers_count":1797,"language":"TypeScript"},{"full_name":"promptfoo/promptfoo","description":"Test your prompts, models, RAGs. Evaluate and compare LLM outputs, catch regressions, and improve prompt quality. LLM evals for OpenAI/Azure GPT, Anthropic Claude, VertexAI Gemini, Ollama, Local & private models like Mistral/Mixtral/Llama with CI/CD","topics":["llm","prompt-engineering","prompts","llmops","prompt-testing","testing","rag","evaluation","evaluation-framework","llm-eval"],"created_at":"2023-04-28T15:48:49Z","pushed_at":"2024-01-28T03:19:41Z","stargazers_count":1796,"language":"TypeScript"},{"full_name":"mnml-theme/prompt","description":"A minimal @z-shell prompt theme.","topics":["prompt","theme","shell","zsh","mnml","git-prompt","git-workflow","prompts","terminal","zsh-configuration"],"created_at":"2020-12-03T19:34:18Z","pushed_at":"2023-11-21T17:44:34Z","stargazers_count":7,"language":"Shell"}],"frecuent_topics":{"prompts":3,"llm":2,"prompt-engineering":2,"llmops":2,"prompt-testing":2}}