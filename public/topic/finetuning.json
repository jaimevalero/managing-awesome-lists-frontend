{"category_type":"topic","category_name":"finetuning","repos_data":[{"full_name":"unslothai/unsloth","description":"Finetune Llama 3.1, Mistral, Phi & Gemma LLMs 2-5x faster with 80% less memory","topics":["ai","finetuning","fine-tuning","llama","llms","lora","mistral","qlora","gemma","llama3"],"created_at":"2023-11-29T16:50:09Z","pushed_at":"2024-09-09T02:55:52Z","stargazers_count":15508,"language":"Python"},{"full_name":"LazyAGI/LazyLLM","description":"Easiest and laziest way for  building multi-agent LLMs applications.","topics":["llms","ai-agent","deep-learning","langchain","llamaindex","rag","agents","data","finetuning","framework"],"created_at":"2024-06-04T05:01:45Z","pushed_at":"2024-09-13T08:56:01Z","stargazers_count":811,"language":"Python"}],"frecuent_topics":{"finetuning":2,"llms":2,"ai":1,"fine-tuning":1,"llama":1}}