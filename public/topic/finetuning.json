{"category_type":"topic","category_name":"finetuning","repos_data":[{"full_name":"linkedin/Liger-Kernel","description":"Efficient Triton Kernels for LLM Training","topics":["llm-training","triton","finetuning","gemma2","llama","llama3","llms","mistral","phi3","triton-kernels"],"created_at":"2024-08-06T17:47:52Z","pushed_at":"2025-12-19T01:01:00Z","stargazers_count":5960,"language":"Makefile"},{"full_name":"LazyAGI/LazyLLM","description":"Easiest and laziest way for  building multi-agent LLMs applications.","topics":["llms","ai-agent","deep-learning","langchain","llamaindex","rag","agents","data","finetuning","framework"],"created_at":"2024-06-04T05:01:45Z","pushed_at":"2025-12-19T10:21:04Z","stargazers_count":3615,"language":"Python"},{"full_name":"IBM/data-prep-kit","description":"Open source project for data preparation for GenAI applications","topics":["data-preparation","finetuning","llm","llmapps","data","data-prep","data-preprocessing","data-preprocessing-pipelines","datacuration","large-language-models"],"created_at":"2024-04-08T23:43:52Z","pushed_at":"2025-12-12T14:48:14Z","stargazers_count":873,"language":"Makefile"}],"frecuent_topics":{"finetuning":3,"llms":2,"data":2,"llm-training":1,"triton":1}}