{"category_type":"topic","category_name":"deepspeed-library","repos_data":[{"full_name":"EleutherAI/gpt-neox","description":"An implementation of model parallel autoregressive transformers on GPUs, based on the Megatron and DeepSpeed libraries","topics":["deepspeed-library","gpt-3","transformers","language-model"],"created_at":"2020-12-22T14:37:54Z","pushed_at":"2024-08-15T21:57:04Z","stargazers_count":6751,"language":"Python"}],"frecuent_topics":{"deepspeed-library":1,"gpt-3":1,"transformers":1,"language-model":1}}