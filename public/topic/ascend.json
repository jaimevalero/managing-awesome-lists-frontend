{"category_type":"topic","category_name":"ascend","repos_data":[{"full_name":"gpustack/gpustack","description":"Performance-Optimized AI Inference on Your GPUs. Unlock it by selecting and tuning the optimal inference engine for your model.","topics":["ascend","cuda","deepseek","distributed-inference","genai","inference","llama","llm","maas","openai"],"created_at":"2024-05-11T03:41:58Z","pushed_at":"2026-01-19T06:06:27Z","stargazers_count":4395,"language":"Python"},{"full_name":"nndeploy/nndeploy","description":"一款简单易用和高性能的AI部署框架 | An Easy-to-Use and High-Performance AI Deployment Framework","topics":["ai","ascend","deep-learning","deployment","diffusers","genai","llm","low-code","low-code-platform","mnn"],"created_at":"2023-08-08T13:13:25Z","pushed_at":"2025-12-27T16:52:38Z","stargazers_count":1688,"language":"CMake"}],"frecuent_topics":{"ascend":2,"genai":2,"llm":2,"cuda":1,"deepseek":1}}