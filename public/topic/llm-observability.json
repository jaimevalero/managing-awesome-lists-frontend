{"category_type":"topic","category_name":"llm-observability","repos_data":[{"full_name":"comet-ml/opik","description":"Debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards.","topics":["open-source","langchain","openai","playground","prompt-engineering","llama-index","llm","llm-evaluation","llm-observability","llmops"],"created_at":"2023-05-10T12:57:13Z","pushed_at":"2025-12-19T15:54:33Z","stargazers_count":16875,"language":"Shell"},{"full_name":"agenta-ai/agenta","description":"The open-source LLMOps platform: prompt playground, prompt management, LLM evaluation, and LLM observability all in one place.","topics":["llm-tools","prompt-engineering","prompt-management","llm-evaluation","llm-framework","rag-evaluation","llm-observability","llm-as-a-judge","llm-monitoring","llm-platform"],"created_at":"2023-04-26T09:54:28Z","pushed_at":"2025-12-19T15:53:06Z","stargazers_count":3538,"language":"Python"}],"frecuent_topics":{"prompt-engineering":2,"llm-evaluation":2,"llm-observability":2,"open-source":1,"langchain":1}}