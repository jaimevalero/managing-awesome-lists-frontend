{"category_type":"topic","category_name":"internlm","repos_data":[{"full_name":"InternLM/lmdeploy","description":"LMDeploy is a toolkit for compressing, deploying, and serving LLMs.","topics":["cuda-kernels","deepspeed","fastertransformer","llm-inference","turbomind","internlm","llama","llm","codellama","llama2"],"created_at":"2023-06-15T12:38:06Z","pushed_at":"2024-05-02T03:43:33Z","stargazers_count":2371,"language":"Python"}],"frecuent_topics":{"cuda-kernels":1,"deepspeed":1,"fastertransformer":1,"llm-inference":1,"turbomind":1}}