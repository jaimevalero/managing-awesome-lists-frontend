{"category_type":"topic","category_name":"attention-mechanism","repos_data":[{"full_name":"lucidrains/reformer-pytorch","description":"Reformer, the efficient Transformer, in Pytorch","topics":["artificial-intelligence","transformers","attention-mechanism","machine-learning","pytorch"],"created_at":"2020-01-09T20:42:37Z","pushed_at":"2023-06-21T14:17:49Z","stargazers_count":2129,"language":"Python"},{"full_name":"kaushalshetty/Structured-Self-Attention","description":"A Structured Self-attentive Sentence Embedding","topics":["attention-mechanism","attention-model","self-attention","self-attentive-rnn","pytorch","deep-learning","python3","attention","visualization","classification"],"created_at":"2018-02-01T07:38:55Z","pushed_at":"2019-09-22T21:00:24Z","stargazers_count":495,"language":"Python"}],"frecuent_topics":{"attention-mechanism":2,"pytorch":2,"artificial-intelligence":1,"transformers":1,"machine-learning":1}}