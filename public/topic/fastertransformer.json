{"category_type":"topic","category_name":"fastertransformer","repos_data":[{"full_name":"InternLM/lmdeploy","description":"LMDeploy is a toolkit for compressing, deploying, and serving LLMs.","topics":["cuda-kernels","deepspeed","fastertransformer","llm-inference","turbomind","internlm","llama","llm","codellama","llama2"],"created_at":"2023-06-15T12:38:06Z","pushed_at":"2024-08-16T04:50:37Z","stargazers_count":3882,"language":"Python"}],"frecuent_topics":{"cuda-kernels":1,"deepspeed":1,"fastertransformer":1,"llm-inference":1,"turbomind":1}}