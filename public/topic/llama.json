{"category_type":"topic","category_name":"llama","repos_data":[{"full_name":"jmorganca/ollama","description":"Get up and running with Llama 3, Mistral, Gemma, and other large language models.","topics":["llama","llm","llama2","llms","go","golang","ollama","mistral"],"created_at":"2023-06-26T19:39:32Z","pushed_at":"2024-05-02T03:14:35Z","stargazers_count":62909,"language":"TypeScript"},{"full_name":"chatchat-space/Langchain-Chatchat","description":"Langchain-Chatchat（原Langchain-ChatGLM）基于 Langchain 与 ChatGLM 等语言模型的本地知识库问答 | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM) QA app with langchain ","topics":["chatglm","langchain","llm","knowledge-base","llama","chatbot","chatgpt","embedding","faiss","fastchat"],"created_at":"2023-03-31T12:12:45Z","pushed_at":"2024-05-01T08:49:50Z","stargazers_count":27555,"language":"Python"},{"full_name":"mudler/LocalAI","description":":robot: The free, Open Source OpenAI alternative. Self-hosted, community-driven and local-first. Drop-in replacement for OpenAI running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. It allows to generate Text, Audio, Video, Images. Also with voice cloning capabilities.","topics":["llama","rwkv","ai","llm","stable-diffusion","api","kubernetes","gpt4all","falcon","tts"],"created_at":"2023-03-18T22:58:02Z","pushed_at":"2024-05-02T04:34:11Z","stargazers_count":19862,"language":"Earthly"},{"full_name":"vllm-project/vllm","description":"A high-throughput and memory-efficient inference and serving engine for LLMs","topics":["gpt","llm","pytorch","llmops","mlops","model-serving","transformer","llm-serving","inference","llama"],"created_at":"2023-02-09T11:23:20Z","pushed_at":"2024-05-02T04:29:55Z","stargazers_count":18791,"language":"Python"},{"full_name":"haotian-liu/LLaVA","description":"[NeurIPS'23 Oral] Visual Instruction Tuning (LLaVA) built towards GPT-4V level capabilities and beyond.","topics":["gpt-4","chatbot","chatgpt","llama","multimodal","llava","foundation-models","instruction-tuning","multi-modality","visual-language-learning"],"created_at":"2023-04-17T16:13:11Z","pushed_at":"2024-05-01T06:37:26Z","stargazers_count":16341,"language":"Python"},{"full_name":"HqWu-HITCS/Awesome-Chinese-LLM","description":"整理开源的中文大语言模型，以规模较小、可私有化部署、训练成本较低的模型为主，包括底座模型，垂直领域微调及应用，数据集与教程等。","topics":["llm","nlp","chatglm","chinese","llama","awesome-lists"],"created_at":"2023-05-22T12:27:03Z","pushed_at":"2024-04-26T13:20:42Z","stargazers_count":10168,"language":"unknown"},{"full_name":"bentoml/OpenLLM","description":"Run any open-source LLMs, such as Llama 2, Mistral, as OpenAI compatible API endpoint in the cloud.","topics":["llm","llmops","model-inference","falcon","fine-tuning","stablelm","llm-serving","llama","mpt","vicuna"],"created_at":"2023-04-19T00:27:52Z","pushed_at":"2024-04-30T19:06:47Z","stargazers_count":8822,"language":"Python"},{"full_name":"LianjiaTech/BELLE","description":"BELLE: Be Everyone's Large Language model Engine（开源中文对话大模型）","topics":["bloom","instruction-set","llama","open-models","gpt-q","instruct-gpt","gpt-evaluation","chinese-nlp","lora","instruct-finetune"],"created_at":"2023-03-17T09:44:11Z","pushed_at":"2024-03-15T04:18:55Z","stargazers_count":7558,"language":"Python"},{"full_name":"serge-chat/serge","description":"A web interface for chatting with Alpaca through llama.cpp. Fully dockerized, with an easy to use API.","topics":["llama","alpaca","docker","fastapi","llamacpp","python","web","svelte","sveltekit","tailwindcss"],"created_at":"2023-03-19T08:33:29Z","pushed_at":"2024-05-02T03:41:59Z","stargazers_count":5545,"language":"Python"},{"full_name":"Facico/Chinese-Vicuna","description":"Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model —— 一个中文低资源的llama+lora方案，结构参考alpaca","topics":["llama","alpaca","chinese","vicuna"],"created_at":"2023-03-23T01:54:50Z","pushed_at":"2024-03-07T09:47:53Z","stargazers_count":4134,"language":"Python"},{"full_name":"higgsfield-ai/higgsfield","description":"Fault-tolerant, highly scalable GPU orchestration, and a machine learning framework designed for training models with billions to trillions of parameters","topics":["cluster-management","deep-learning","distributed","llama","llama2","llm","machine-learning","mlops","pytorch"],"created_at":"2018-05-26T22:47:43Z","pushed_at":"2024-03-23T13:01:18Z","stargazers_count":3254,"language":"Jupyter Notebook"},{"full_name":"InternLM/lmdeploy","description":"LMDeploy is a toolkit for compressing, deploying, and serving LLMs.","topics":["cuda-kernels","deepspeed","fastertransformer","llm-inference","turbomind","internlm","llama","llm","codellama","llama2"],"created_at":"2023-06-15T12:38:06Z","pushed_at":"2024-05-02T03:43:33Z","stargazers_count":2371,"language":"Python"},{"full_name":"zjunlp/KnowLM","description":"An Open-sourced Knowledgable Large Language Model Framework.","topics":["llama","large-language-models","pre-trained-language-models","language-model","instruction-following","deep-learning","chinese","english","instructions","models"],"created_at":"2023-04-01T03:45:31Z","pushed_at":"2024-04-21T08:35:14Z","stargazers_count":1016,"language":"Python"},{"full_name":"GaryYufei/AlignLLMHumanSurvey","description":"Aligning Large Language Models with Human: A Survey","topics":["chatgpt","gpt-4","large-language-models","llms","rlhf","supervised-finetuning","survey","awesome","chinese-llama","llama"],"created_at":"2023-07-23T06:41:56Z","pushed_at":"2023-09-11T03:38:05Z","stargazers_count":603,"language":"unknown"},{"full_name":"pleisto/flappy","description":"Production-Ready LLM Agent SDK for Every Developer","topics":["agent","chatgpt","generative-ai","llm","rewoo","llama","transformers"],"created_at":"2023-09-15T18:09:15Z","pushed_at":"2024-04-19T20:02:28Z","stargazers_count":304,"language":"Rust"}],"frecuent_topics":{"llama":15,"llm":9,"chatgpt":4,"llama2":3,"chinese":3}}