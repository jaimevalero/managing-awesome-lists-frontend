{"category_type":"topic","category_name":"llama","repos_data":[{"full_name":"jmorganca/ollama","description":"Get up and running with Llama 3.2, Mistral, Gemma 2, and other large language models.","topics":["llama","llm","llama2","llms","go","golang","ollama","mistral","gemma","llama3"],"created_at":"2023-06-26T19:39:32Z","pushed_at":"2024-12-01T05:22:08Z","stargazers_count":100365,"language":"TypeScript"},{"full_name":"ollama/ollama","description":"Get up and running with Llama 3.2, Mistral, Gemma 2, and other large language models.","topics":["llama","llm","llama2","llms","go","golang","ollama","mistral","gemma","llama3"],"created_at":"2023-06-26T19:39:32Z","pushed_at":"2024-12-01T05:22:08Z","stargazers_count":100364,"language":"TypeScript"},{"full_name":"ggerganov/llama.cpp","description":"LLM inference in C/C++","topics":["llama","ggml"],"created_at":"2023-03-10T18:58:00Z","pushed_at":"2024-12-02T07:04:11Z","stargazers_count":68584,"language":"Makefile"},{"full_name":"chatchat-space/Langchain-Chatchat","description":"Langchain-Chatchat（原Langchain-ChatGLM）基于 Langchain 与 ChatGLM, Qwen 与 Llama 等语言模型的 RAG 与 Agent 应用 | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM, Qwen and Llama) RAG and Agent app with langchain ","topics":["chatglm","langchain","llm","knowledge-base","llama","chatbot","chatgpt","embedding","faiss","fastchat"],"created_at":"2023-03-31T12:12:45Z","pushed_at":"2024-11-29T05:06:44Z","stargazers_count":32269,"language":"Python"},{"full_name":"vllm-project/vllm","description":"A high-throughput and memory-efficient inference and serving engine for LLMs","topics":["gpt","llm","pytorch","llmops","mlops","model-serving","transformer","llm-serving","inference","llama"],"created_at":"2023-02-09T11:23:20Z","pushed_at":"2024-12-02T05:36:36Z","stargazers_count":31122,"language":"Python"},{"full_name":"mudler/LocalAI","description":":robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P inference","topics":["llama","rwkv","ai","llm","stable-diffusion","api","kubernetes","gpt4all","tts","musicgen"],"created_at":"2023-03-18T22:58:02Z","pushed_at":"2024-12-01T21:45:00Z","stargazers_count":26579,"language":"Earthly"},{"full_name":"unslothai/unsloth","description":"Finetune Llama 3.2, Mistral, Phi, Qwen 2.5 & Gemma LLMs 2-5x faster with 80% less memory","topics":["ai","finetuning","fine-tuning","llama","llms","lora","mistral","qlora","gemma","llama3"],"created_at":"2023-11-29T16:50:09Z","pushed_at":"2024-12-01T10:36:19Z","stargazers_count":18753,"language":"Python"},{"full_name":"HqWu-HITCS/Awesome-Chinese-LLM","description":"整理开源的中文大语言模型，以规模较小、可私有化部署、训练成本较低的模型为主，包括底座模型，垂直领域微调及应用，数据集与教程等。","topics":["llm","nlp","chatglm","chinese","llama","awesome-lists"],"created_at":"2023-05-22T12:27:03Z","pushed_at":"2024-09-19T11:06:18Z","stargazers_count":16280,"language":"unknown"},{"full_name":"bentoml/OpenLLM","description":"Run any open-source LLMs, such as Llama, Mistral, as OpenAI compatible API endpoint in the cloud.","topics":["llm","llmops","model-inference","fine-tuning","llm-serving","llama","vicuna","bentoml","llama2","llm-inference"],"created_at":"2023-04-19T00:27:52Z","pushed_at":"2024-11-26T06:30:21Z","stargazers_count":10142,"language":"Python"},{"full_name":"sgl-project/sglang","description":"SGLang is a fast serving framework for large language models and vision language models.","topics":["cuda","inference","llama","llava","llm","llm-serving","moe","pytorch","transformer","vlm"],"created_at":"2024-01-08T04:15:52Z","pushed_at":"2024-12-02T07:17:44Z","stargazers_count":6310,"language":"Python"},{"full_name":"serge-chat/serge","description":"A web interface for chatting with Alpaca through llama.cpp. Fully dockerized, with an easy to use API.","topics":["llama","alpaca","docker","fastapi","llamacpp","python","web","svelte","sveltekit","tailwindcss"],"created_at":"2023-03-19T08:33:29Z","pushed_at":"2024-11-29T08:34:25Z","stargazers_count":5684,"language":"Python"},{"full_name":"InternLM/lmdeploy","description":"LMDeploy is a toolkit for compressing, deploying, and serving LLMs.","topics":["cuda-kernels","deepspeed","fastertransformer","llm-inference","turbomind","internlm","llama","llm","codellama","llama2"],"created_at":"2023-06-15T12:38:06Z","pushed_at":"2024-12-02T06:01:05Z","stargazers_count":4743,"language":"Python"},{"full_name":"linkedin/Liger-Kernel","description":"Efficient Triton Kernels for LLM Training","topics":["llm-training","triton","finetuning","gemma2","llama","llama3","llms","mistral","phi3","triton-kernels"],"created_at":"2024-08-06T17:47:52Z","pushed_at":"2025-02-09T14:52:05Z","stargazers_count":4378,"language":"Makefile"},{"full_name":"higgsfield-ai/higgsfield","description":"Fault-tolerant, highly scalable GPU orchestration, and a machine learning framework designed for training models with billions to trillions of parameters","topics":["cluster-management","deep-learning","distributed","llama","llama2","llm","machine-learning","mlops","pytorch"],"created_at":"2018-05-26T22:47:43Z","pushed_at":"2024-05-25T17:43:07Z","stargazers_count":3345,"language":"Jupyter Notebook"},{"full_name":"GaryYufei/AlignLLMHumanSurvey","description":"Aligning Large Language Models with Human: A Survey","topics":["chatgpt","gpt-4","large-language-models","llms","rlhf","supervised-finetuning","survey","awesome","chinese-llama","llama"],"created_at":"2023-07-23T06:41:56Z","pushed_at":"2023-09-11T03:38:05Z","stargazers_count":703,"language":"unknown"},{"full_name":"ngxson/wllama","description":"WebAssembly binding for llama.cpp - Enabling on-browser LLM inference","topics":["llama","llamacpp","llm","wasm","webassembly"],"created_at":"2024-03-13T23:18:27Z","pushed_at":"2024-12-01T15:21:07Z","stargazers_count":451,"language":"CMake"},{"full_name":"llm-ui-kit/llm-ui","description":"The React library for LLMs","topics":["component-library","react","chatgpt","claude","generative-ai","llm","openai","llama","markdown"],"created_at":"2024-03-31T07:15:54Z","pushed_at":"2024-06-27T16:17:26Z","stargazers_count":412,"language":"JavaScript"},{"full_name":"pleisto/flappy","description":"Production-Ready LLM Agent SDK for Every Developer","topics":["agent","chatgpt","generative-ai","llm","rewoo","llama","transformers"],"created_at":"2023-09-15T18:09:15Z","pushed_at":"2024-04-19T20:02:28Z","stargazers_count":311,"language":"Rust"},{"full_name":"longevity-genie/just-chat","description":"Make your LLM agent and chat with it simple and fast!","topics":["agents","ai","chat","chatbot","llms","agentic-ai","deepseek","groq","llama"],"created_at":"2025-01-29T14:28:08Z","pushed_at":"2025-03-26T02:08:31Z","stargazers_count":55,"language":"Python"},{"full_name":"SoftCreatR/php-mistral-ai-sdk","description":"A powerful and easy-to-use PHP SDK for the Mistral AI API, allowing seamless integration of advanced AI-powered features into your PHP projects.","topics":["ai","api","api-client","api-wrapper","artificial-intelligence","gpt","gpt-3","gpt-4","hacktoberfest","llama"],"created_at":"2024-02-03T06:16:48Z","pushed_at":"2024-10-08T08:48:29Z","stargazers_count":6,"language":"PHP"}],"frecuent_topics":{"llama":20,"llm":13,"llms":6,"llama2":5,"mistral":4}}