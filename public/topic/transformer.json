{"category_type":"topic","category_name":"transformer","repos_data":[{"full_name":"huggingface/transformers","description":"ü§ó Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.","topics":["nlp","natural-language-processing","pytorch","language-model","tensorflow","bert","language-models","pytorch-transformers","nlp-library","transformer"],"created_at":"2018-10-29T13:56:00Z","pushed_at":"2024-11-29T23:13:12Z","stargazers_count":135733,"language":"Python"},{"full_name":"labmlai/annotated_deep_learning_paper_implementations","description":"üßë‚Äçüè´ 60+ Implementations/tutorials of deep learning papers with side-by-side notes üìù; including transformers (original, xl, switch, feedback, vit, ...), optimizers (adam, adabelief, sophia, ...), gans(cyclegan, stylegan2, ...), üéÆ reinforcement learning (ppo, dqn), capsnet, distillation, ... üß†","topics":["deep-learning","deep-learning-tutorial","pytorch","gan","transformers","reinforcement-learning","optimizers","neural-networks","transformer","machine-learning"],"created_at":"2020-08-25T02:29:34Z","pushed_at":"2024-08-24T09:18:59Z","stargazers_count":57338,"language":"Python"},{"full_name":"vllm-project/vllm","description":"A high-throughput and memory-efficient inference and serving engine for LLMs","topics":["gpt","llm","pytorch","llmops","mlops","model-serving","transformer","llm-serving","inference","llama"],"created_at":"2023-02-09T11:23:20Z","pushed_at":"2024-12-02T05:36:36Z","stargazers_count":31122,"language":"Python"},{"full_name":"open-mmlab/mmsegmentation","description":"OpenMMLab Semantic Segmentation Toolbox and Benchmark.","topics":["semantic-segmentation","pytorch","pspnet","deeplabv3","transformer","swin-transformer","realtime-segmentation","vessel-segmentation","retinal-vessel-segmentation","image-segmentation"],"created_at":"2020-06-14T04:32:33Z","pushed_at":"2024-08-13T08:53:34Z","stargazers_count":8349,"language":"Python"},{"full_name":"google/trax","description":"Trax ‚Äî Deep Learning with Clear Code and Speed","topics":["jax","numpy","deep-learning","deep-reinforcement-learning","machine-learning","transformer","reinforcement-learning"],"created_at":"2019-10-05T15:09:14Z","pushed_at":"2024-09-10T20:43:39Z","stargazers_count":8108,"language":"Python"},{"full_name":"EleutherAI/lm-evaluation-harness","description":"A framework for few-shot evaluation of language models.","topics":["evaluation-framework","language-model","transformer"],"created_at":"2020-08-28T00:09:15Z","pushed_at":"2024-12-01T12:31:51Z","stargazers_count":7099,"language":"Python"},{"full_name":"sgl-project/sglang","description":"SGLang is a fast serving framework for large language models and vision language models.","topics":["cuda","inference","llama","llava","llm","llm-serving","moe","pytorch","transformer","vlm"],"created_at":"2024-01-08T04:15:52Z","pushed_at":"2024-12-02T07:17:44Z","stargazers_count":6310,"language":"Python"},{"full_name":"codertimo/BERT-pytorch","description":"Google AI 2018 BERT pytorch implementation","topics":["bert","transformer","pytorch","nlp","language-model"],"created_at":"2018-10-15T12:58:15Z","pushed_at":"2023-09-15T12:57:08Z","stargazers_count":6233,"language":"Python"},{"full_name":"NVIDIA/FasterTransformer","description":"Transformer related optimization, including BERT, GPT","topics":["pytorch","transformer","gpt","bert"],"created_at":"2021-04-02T21:36:33Z","pushed_at":"2024-03-27T11:25:30Z","stargazers_count":5917,"language":"CMake"},{"full_name":"guillaume-be/rust-bert","description":"Rust native ready-to-use NLP pipelines and transformer-based models (BERT, DistilBERT, GPT2,...)","topics":["deep-learning","nlp","transformer","bert","rust-lang","rust","machine-learning","ner","sentiment-analysis","question-answering"],"created_at":"2020-01-25T09:40:07Z","pushed_at":"2024-09-29T14:13:25Z","stargazers_count":2677,"language":"Rust"},{"full_name":"huggingface/pytorch-openai-transformer-lm","description":"üê•A PyTorch implementation of OpenAI's finetuned transformer language model with a script to import the weights pre-trained by OpenAI","topics":["neural-networks","pytorch","openai","language-model","transformer"],"created_at":"2018-06-13T14:02:41Z","pushed_at":"2021-08-09T16:17:12Z","stargazers_count":1512,"language":"Python"},{"full_name":"lemonhu/NER-BERT-pytorch","description":"PyTorch solution of named entity recognition task Using Google AI's pre-trained BERT model.","topics":["ner","named-entity-recognition","entity-extraction","chinese-ner","google-bert","transformer","msra","information-extraction","pytorch"],"created_at":"2019-01-04T08:13:41Z","pushed_at":"2023-03-30T13:57:17Z","stargazers_count":441,"language":"Python"},{"full_name":"barissayil/SentimentAnalysis","description":"Sentiment analysis neural network trained by fine-tuning BERT, ALBERT, or DistilBERT on the Stanford Sentiment Treebank.","topics":["bert","nlp","machine-learning","pytorch","pytorch-implementation","vuejs","flask","transformer","huggingface","huggingface-transformer"],"created_at":"2019-12-27T11:54:06Z","pushed_at":"2023-06-12T21:34:19Z","stargazers_count":367,"language":"Python"},{"full_name":"andresinaka/Transformer","description":"Easy Attributed String Creator","topics":["nsattributedstring","online-editor","swift","objective-c","transformer"],"created_at":"2017-10-24T14:34:38Z","pushed_at":"2020-05-18T13:53:03Z","stargazers_count":281,"language":"JavaScript"},{"full_name":"L0SG/relational-rnn-pytorch","description":"An implementation of DeepMind's Relational Recurrent Neural Networks (NeurIPS 2018) in PyTorch.","topics":["pytorch","language-model","word-language-model","language-modeling","deep-learning","recurrent-neural-networks","deepmind","transformer","self-attention"],"created_at":"2018-08-21T07:57:41Z","pushed_at":"2018-12-27T05:38:23Z","stargazers_count":245,"language":"Python"},{"full_name":"leviswind/pytorch-transformer","description":"pytorch implementation of Attention is all you need","topics":["pytorch","attention-is-all-you-need","translation","transformer"],"created_at":"2018-01-05T08:00:01Z","pushed_at":"2021-06-16T06:35:54Z","stargazers_count":240,"language":"Python"}],"frecuent_topics":{"transformer":16,"pytorch":12,"language-model":5,"bert":5,"nlp":4}}