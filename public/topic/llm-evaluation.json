{"category_type":"topic","category_name":"llm-evaluation","repos_data":[{"full_name":"Marker-Inc-Korea/AutoRAG","description":"AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation","topics":["analysis","automl","benchmarking","document-parser","embeddings","evaluation","llm","llm-evaluation","llm-ops","open-source"],"created_at":"2024-01-10T12:25:00Z","pushed_at":"2024-12-08T06:48:21Z","stargazers_count":2884,"language":"Python"},{"full_name":"agenta-ai/agenta","description":"The open-source LLMOps platform: prompt playground, prompt management, LLM evaluation, and LLM Observability all in one place.","topics":["llm-tools","prompt-engineering","prompt-management","llm-evaluation","llm-framework","rag-evaluation","llm-observability","llm-as-a-judge","llm-monitoring","llm-platform"],"created_at":"2023-04-26T09:54:28Z","pushed_at":"2024-12-01T17:56:49Z","stargazers_count":1473,"language":"Dockerfile"}],"frecuent_topics":{"llm-evaluation":2,"analysis":1,"automl":1,"benchmarking":1,"document-parser":1}}