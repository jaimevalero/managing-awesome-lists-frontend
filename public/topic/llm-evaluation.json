{"category_type":"topic","category_name":"llm-evaluation","repos_data":[{"full_name":"comet-ml/opik","description":"Debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards.","topics":["open-source","langchain","openai","playground","prompt-engineering","llama-index","llm","llm-evaluation","llm-observability","llmops"],"created_at":"2023-05-10T12:57:13Z","pushed_at":"2025-12-19T15:54:33Z","stargazers_count":16875,"language":"Shell"},{"full_name":"jeinlee1991/chinese-llm-benchmark","description":"ReLEè¯„æµ‹ï¼šä¸­æ–‡AIå¤§æ¨¡å‹èƒ½åŠ›è¯„æµ‹ï¼ˆæŒç»­æ›´æ–°ï¼‰ï¼šç›®å‰å·²å›Šæ‹¬335ä¸ªå¤§æ¨¡å‹ï¼Œè¦†ç›–chatgptã€gpt-5.2ã€o4-miniã€è°·æ­Œgemini-3-proã€Claude-4.5ã€æ–‡å¿ƒERNIE-X1.1ã€ERNIE-5.0-Thinkingã€qwen3-maxã€ç™¾å·ã€è®¯é£æ˜Ÿç«ã€å•†æ±¤senseChatç­‰å•†ç”¨æ¨¡å‹ï¼Œ ä»¥åŠkimi-k2ã€ernie4.5ã€minimax-M2ã€deepseek-v3.2ã€qwen3-2507ã€llama4ã€æ™ºè°±GLM-4.6ã€gemma3ã€mistralç­‰å¼€æºå¤§æ¨¡å‹ã€‚ä¸ä»…æä¾›æ’è¡Œæ¦œï¼Œä¹Ÿæä¾›è§„æ¨¡è¶…200ä¸‡çš„å¤§æ¨¡å‹ç¼ºé™·åº“ï¼æ–¹ä¾¿å¹¿å¤§ç¤¾åŒºç ”ç©¶åˆ†æã€æ”¹è¿›å¤§æ¨¡å‹ã€‚","topics":["agentic-ai","artificial-intelligence","llm-agent","llm-evaluation"],"created_at":"2023-06-04T07:23:20Z","pushed_at":"2025-12-19T01:46:03Z","stargazers_count":5296,"language":"unknown"},{"full_name":"Giskard-AI/giskard-oss","description":"ğŸ¢ Open-Source Evaluation & Testing library for LLM Agents","topics":["mlops","ml-validation","ml-testing","ai-testing","llmops","responsible-ai","fairness-ai","trustworthy-ai","llm-eval","llm-evaluation"],"created_at":"2022-03-06T21:45:37Z","pushed_at":"2025-11-18T11:06:33Z","stargazers_count":5064,"language":"Shell"},{"full_name":"Marker-Inc-Korea/AutoRAG","description":"AutoRAG: An Open-Source Framework for Retrieval-Augmented Generation (RAG) Evaluation & Optimization with AutoML-Style Automation","topics":["analysis","automl","benchmarking","document-parser","embeddings","evaluation","llm","llm-evaluation","llm-ops","open-source"],"created_at":"2024-01-10T12:25:00Z","pushed_at":"2025-11-20T17:57:18Z","stargazers_count":4486,"language":"Python"},{"full_name":"agenta-ai/agenta","description":"The open-source LLMOps platform: prompt playground, prompt management, LLM evaluation, and LLM observability all in one place.","topics":["llm-tools","prompt-engineering","prompt-management","llm-evaluation","llm-framework","rag-evaluation","llm-observability","llm-as-a-judge","llm-monitoring","llm-platform"],"created_at":"2023-04-26T09:54:28Z","pushed_at":"2025-12-19T15:53:06Z","stargazers_count":3538,"language":"Python"}],"frecuent_topics":{"llm-evaluation":5,"open-source":2,"prompt-engineering":2,"llm":2,"llm-observability":2}}