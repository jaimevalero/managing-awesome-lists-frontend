{"category_type":"topic","category_name":"data-pipeline","repos_data":[{"full_name":"snowplow/snowplow","description":"The leader in Customer Data Infrastructure","topics":["snowplow","analytics","data","data-pipeline","data-collection","product-analytics","marketing-analytics","snowplow-pipeline","snowplow-events"],"created_at":"2012-03-01T13:02:21Z","pushed_at":"2025-06-04T15:51:26Z","stargazers_count":6995,"language":"CSS"},{"full_name":"dagu-go/dagu","description":"A self-contained, lightweight workflow engine with a built-in Web UI. Define workflows in a simple, declarative YAML format. Execute them anywhere, compose complex pipelines, and distribute tasks. Zero dependencies: runs entirely on the file system and OS without an external database.","topics":["cron","task-scheduler","continuous-delivery","workflow-engine","workflow-scheduler","workflow-orchestration","devops","data-pipeline","job-scheduler","task-automation"],"created_at":"2022-04-22T13:00:42Z","pushed_at":"2026-01-18T17:36:35Z","stargazers_count":2991,"language":"Makefile"},{"full_name":"dagu-org/dagu","description":"A self-contained, lightweight workflow engine with a built-in Web UI. Define workflows in a simple, declarative YAML format. Execute them anywhere, compose complex pipelines, and distribute tasks. Zero dependencies: runs entirely on the file system and OS without an external database.","topics":["cron","task-scheduler","continuous-delivery","workflow-engine","workflow-scheduler","workflow-orchestration","devops","data-pipeline","job-scheduler","task-automation"],"created_at":"2022-04-22T13:00:42Z","pushed_at":"2026-01-18T17:36:35Z","stargazers_count":2991,"language":"Makefile"},{"full_name":"reugn/go-streams","description":"A lightweight stream processing library for Go","topics":["stream-processing","pipeline","etl","kafka","data-stream","kafka-streams","streams","redis","pulsar","data-pipeline"],"created_at":"2019-04-30T17:28:15Z","pushed_at":"2026-01-14T15:05:35Z","stargazers_count":2152,"language":"Go"},{"full_name":"pydoit/doit","description":"CLI task management & automation tool","topics":["python","build-tool","build-automation","task-runner","build-system","workflow-management","data-pipeline","workflow","workflow-automation","data-science"],"created_at":"2014-02-14T22:21:23Z","pushed_at":"2026-01-10T21:17:58Z","stargazers_count":2003,"language":"Python"},{"full_name":"msamogh/nonechucks","description":"Deal with bad samples in your dataset dynamically, use Transforms as Filters, and more!","topics":["pytorch","data-processing","data-preprocessing","data-pipeline","data-cleaning","preprocessing","machine-learning","torch"],"created_at":"2018-10-05T08:48:46Z","pushed_at":"2022-09-22T23:03:31Z","stargazers_count":377,"language":"Python"},{"full_name":"scicloj/scicloj.ml","description":"A Clojure machine learning library","topics":["machine-learning","data-science","data-pipeline","hyperparameter-optimization","classification","regression","scicloj","nlp","clojure","clustering"],"created_at":"2021-03-18T13:58:42Z","pushed_at":"2025-11-02T13:32:54Z","stargazers_count":240,"language":"Clojure"},{"full_name":"tejzpr/ordered-concurrently","description":"Ordered-concurrently a library for concurrent processing with ordered output in Go. Process work concurrently and returns output in a channel in the order of input. It is useful in concurrently processing items in a queue, and get output in the order provided by the queue.","topics":["concurrent","golang","golang-library","data-science","data-pipeline","parallel-computing","concurrent-data-structure","ordered","parallel"],"created_at":"2021-02-28T17:56:05Z","pushed_at":"2023-04-24T23:24:20Z","stargazers_count":44,"language":"Go"}],"frecuent_topics":{"data-pipeline":8,"data-science":3,"cron":2,"task-scheduler":2,"continuous-delivery":2}}