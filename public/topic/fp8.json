{"category_type":"topic","category_name":"fp8","repos_data":[{"full_name":"NVIDIA/TransformerEngine","description":"A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper and Ada GPUs, to provide better performance with lower memory utilization in both training and inference.","topics":["cuda","deep-learning","gpu","machine-learning","python","pytorch","fp8","jax"],"created_at":"2022-09-20T15:20:26Z","pushed_at":"2024-12-20T05:32:41Z","stargazers_count":2035,"language":"Shell"}],"frecuent_topics":{"cuda":1,"deep-learning":1,"gpu":1,"machine-learning":1,"python":1}}