{"category_type":"topic","category_name":"question-answering","repos_data":[{"full_name":"deepset-ai/haystack","description":":mag: LLM orchestration framework to build customizable, production-ready LLM applications. Connect components (models, vector DBs, file converters) to pipelines or agents that can interact with your data. With advanced retrieval methods, it's best suited for building RAG, question answering, semantic search or conversational agent chatbots.","topics":["nlp","question-answering","bert","language-model","pytorch","semantic-search","squad","information-retrieval","summarization","transformers"],"created_at":"2019-11-14T09:05:28Z","pushed_at":"2024-05-02T02:59:31Z","stargazers_count":13702,"language":"Python"},{"full_name":"deepmipt/DeepPavlov","description":"An open source library for deep learning end-to-end dialog systems and chatbots.","topics":["bot","nlp","chatbot","dialogue-systems","question-answering","chitchat","slot-filling","intent-classification","entity-extraction","named-entity-recognition"],"created_at":"2017-11-17T14:35:29Z","pushed_at":"2024-04-21T11:02:41Z","stargazers_count":6547,"language":"Python"},{"full_name":"guillaume-be/rust-bert","description":"Rust native ready-to-use NLP pipelines and transformer-based models (BERT, DistilBERT, GPT2,...)","topics":["deep-learning","nlp","transformer","bert","rust-lang","rust","machine-learning","ner","sentiment-analysis","question-answering"],"created_at":"2020-01-25T09:40:07Z","pushed_at":"2024-03-07T15:46:07Z","stargazers_count":2424,"language":"Rust"},{"full_name":"sindresorhus/amas","description":"Awesome & Marvelous Amas","topics":["ama","ask-me-anything","question-answering","meta","ask","list","awesome","awesome-list"],"created_at":"2015-07-04T11:11:08Z","pushed_at":"2024-03-12T11:44:21Z","stargazers_count":1399,"language":"unknown"},{"full_name":"atfortes/Awesome-LLM-Reasoning","description":"Reasoning in Large Language Models: Papers and Resources, including Chain-of-Thought, Instruction-Tuning and Multimodality. ","topics":["language-models","reasoning","prompt","question-answering","in-context-learning","chatgpt","chain-of-thought","prompt-engineering","cot","awesome"],"created_at":"2022-11-05T08:03:53Z","pushed_at":"2024-04-24T02:40:38Z","stargazers_count":1100,"language":"unknown"},{"full_name":"seriousran/awesome-qa","description":"ðŸ˜Ž A curated list of the Question Answering (QA)","topics":["question-answering","nlp","machine-comprehension","awesome","awesome-list","squad","bert","watson","deepqa"],"created_at":"2018-07-20T02:31:32Z","pushed_at":"2022-01-13T02:23:01Z","stargazers_count":750,"language":"unknown"},{"full_name":"nlpodyssey/cybertron","description":"Cybertron: the home planet of the Transformers in Go","topics":["bart","bert","machine-translation","question-answering","zero-shot-classification","bert-as-service","transformers","huggingface","text-classification","named-entity-recognition"],"created_at":"2022-06-21T13:45:54Z","pushed_at":"2024-01-10T21:57:15Z","stargazers_count":258,"language":"Go"},{"full_name":"backprop-ai/backprop","description":"Backprop makes it simple to use, finetune, and deploy state-of-the-art ML models.","topics":["natural-language-processing","nlp","question-answering","bert","language-model","text-classification","multilingual-models","image-classification","fine-tuning","transfer-learning"],"created_at":"2020-10-30T15:25:14Z","pushed_at":"2021-05-03T09:15:25Z","stargazers_count":240,"language":"Python"}],"frecuent_topics":{"question-answering":8,"nlp":5,"bert":5,"awesome":3,"language-model":2}}