{"category_type":"topic","category_name":"llmops","repos_data":[{"full_name":"vllm-project/vllm","description":"A high-throughput and memory-efficient inference and serving engine for LLMs","topics":["gpt","llm","pytorch","llmops","mlops","model-serving","transformer","llm-serving","inference","llama"],"created_at":"2023-02-09T11:23:20Z","pushed_at":"2024-12-02T05:36:36Z","stargazers_count":31122,"language":"Python"},{"full_name":"bentoml/OpenLLM","description":"Run any open-source LLMs, such as Llama, Mistral, as OpenAI compatible API endpoint in the cloud.","topics":["llm","llmops","model-inference","fine-tuning","llm-serving","llama","vicuna","bentoml","llama2","llm-inference"],"created_at":"2023-04-19T00:27:52Z","pushed_at":"2024-11-26T06:30:21Z","stargazers_count":10142,"language":"Python"},{"full_name":"bentoml/BentoML","description":"The easiest way to serve AI apps and models - Build Model Inference APIs, Job queues, LLM apps, Multi-model pipelines, and more!","topics":["model-serving","mlops","llmops","generative-ai","llm-inference","model-inference-service","inference-platform","deep-learning","llm-serving","machine-learning"],"created_at":"2019-04-02T01:39:27Z","pushed_at":"2025-03-12T10:03:16Z","stargazers_count":7469,"language":"Python"},{"full_name":"explodinggradients/ragas","description":"Supercharge Your LLM Application Evaluations üöÄ","topics":["llm","llmops","evaluation"],"created_at":"2023-05-08T17:48:04Z","pushed_at":"2024-11-29T07:20:20Z","stargazers_count":7406,"language":"Python"},{"full_name":"langfuse/langfuse","description":"ü™¢ Open source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets. Integrates with LlamaIndex, Langchain, OpenAI SDK, LiteLLM, and more. üçäYC W23 ","topics":["analytics","llm","llmops","gpt","large-language-models","openai","self-hosted","ycombinator","monitoring","observability"],"created_at":"2023-05-18T17:47:09Z","pushed_at":"2024-11-29T23:20:37Z","stargazers_count":6853,"language":"JavaScript"},{"full_name":"Portkey-AI/gateway","description":"A Blazing Fast AI Gateway with integrated Guardrails. Route to 200+ LLMs, 50+ AI Guardrails with 1 fast & friendly API.","topics":["gateway","generative-ai","llmops","llms","prompt-engineering","ai-gateway","langchain","llama-index","openai","router"],"created_at":"2023-08-23T11:52:47Z","pushed_at":"2024-11-29T19:26:26Z","stargazers_count":6370,"language":"TypeScript"},{"full_name":"typpo/promptfoo","description":"Test your prompts, agents, and RAGs. Red teaming, pentesting, and vulnerability scanning for LLMs. Compare performance of GPT, Claude, Gemini, Llama, and more. Simple declarative configs with command line and CI/CD integration.","topics":["llm","prompt-engineering","prompts","llmops","prompt-testing","testing","rag","evaluation","evaluation-framework","llm-eval"],"created_at":"2023-04-28T15:48:49Z","pushed_at":"2024-12-02T04:03:49Z","stargazers_count":4888,"language":"TypeScript"},{"full_name":"Giskard-AI/giskard","description":"üê¢ Open-Source Evaluation & Testing for ML & LLM systems","topics":["mlops","ml-validation","ml-testing","ai-testing","ai-safety","ml-safety","llmops","ethical-artificial-intelligence","responsible-ai","fairness-ai"],"created_at":"2022-03-06T21:45:37Z","pushed_at":"2024-12-01T23:45:37Z","stargazers_count":4100,"language":"Shell"},{"full_name":"tensorchord/envd","description":"üèïÔ∏è Reproducible development environment","topics":["developer-tools","development-environment","docker","buildkit","hacktoberfest","llmops","mlops","mlops-workflow","model-serving"],"created_at":"2022-04-11T09:04:19Z","pushed_at":"2024-10-07T02:43:57Z","stargazers_count":2055,"language":"Makefile"},{"full_name":"dagworks-inc/burr","description":"Build applications that make decisions (chatbots, agents, simulations, etc...). Monitor, trace, persist, and execute on your own infrastructure.","topics":["burr","dags","graphs","llmops","llms","mlops","persistent-data-structure","state-machine","state-management","visibility"],"created_at":"2024-01-29T23:27:07Z","pushed_at":"2024-12-06T19:47:21Z","stargazers_count":1354,"language":"Python"},{"full_name":"tensorzero/tensorzero","description":"TensorZero creates a feedback loop for optimizing LLM applications ‚Äî turning production data into smarter, faster, and cheaper models.","topics":["ai","artificial-intelligence","deep-learning","gpt","llm","llmops","llms","machine-learning","rust","ml"],"created_at":"2024-07-16T21:00:53Z","pushed_at":"2024-12-06T22:26:35Z","stargazers_count":1031,"language":"Rust"},{"full_name":"mani-kantap/llm-inference-solutions","description":"A collection of all available inference solutions for the LLMs","topics":["llm-inference","llm-serving","llmops"],"created_at":"2023-07-23T20:39:23Z","pushed_at":"2024-09-18T02:33:49Z","stargazers_count":74,"language":"unknown"}],"frecuent_topics":{"llmops":12,"llm":6,"mlops":5,"llm-serving":4,"gpt":3}}