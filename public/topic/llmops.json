{"category_type":"topic","category_name":"llmops","repos_data":[{"full_name":"vllm-project/vllm","description":"A high-throughput and memory-efficient inference and serving engine for LLMs","topics":["gpt","llm","pytorch","llmops","mlops","model-serving","transformer","llm-serving","inference","llama"],"created_at":"2023-02-09T11:23:20Z","pushed_at":"2024-09-13T09:20:14Z","stargazers_count":26603,"language":"Python"},{"full_name":"bentoml/OpenLLM","description":"Run any open-source LLMs, such as Llama 3.1, Gemma, as OpenAI compatible API endpoint in the cloud.","topics":["llm","llmops","model-inference","falcon","fine-tuning","stablelm","llm-serving","llama","mpt","vicuna"],"created_at":"2023-04-19T00:27:52Z","pushed_at":"2024-09-09T17:24:10Z","stargazers_count":9726,"language":"Python"},{"full_name":"bentoml/BentoML","description":"The easiest way to serve AI apps and models - Build reliable Inference APIs, LLM apps, Multi-model chains, RAG service, and much more!","topics":["model-serving","mlops","llmops","generative-ai","llm-inference","model-inference-service","inference-platform","deep-learning","llm-serving","machine-learning"],"created_at":"2019-04-02T01:39:27Z","pushed_at":"2024-10-12T07:21:00Z","stargazers_count":7062,"language":"Python"},{"full_name":"explodinggradients/ragas","description":"Evaluation framework for your Retrieval Augmented Generation (RAG) pipelines","topics":["llm","llmops"],"created_at":"2023-05-08T17:48:04Z","pushed_at":"2024-09-13T05:49:23Z","stargazers_count":6550,"language":"Python"},{"full_name":"Portkey-AI/gateway","description":"A Blazing Fast AI Gateway with integrated Guardrails. Route to 200+ LLMs, 50+ AI Guardrails with 1 fast & friendly API.","topics":["gateway","generative-ai","llmops","llms","prompt-engineering","ai-gateway","langchain","llama-index","openai","router"],"created_at":"2023-08-23T11:52:47Z","pushed_at":"2024-09-13T07:46:36Z","stargazers_count":5851,"language":"TypeScript"},{"full_name":"langfuse/langfuse","description":"ü™¢ Open source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets. Integrates with LlamaIndex, Langchain, OpenAI SDK, LiteLLM, and more. üçäYC W23 ","topics":["analytics","llm","llmops","gpt","large-language-models","openai","self-hosted","ycombinator","monitoring","observability"],"created_at":"2023-05-18T17:47:09Z","pushed_at":"2024-09-13T13:04:48Z","stargazers_count":5577,"language":"JavaScript"},{"full_name":"typpo/promptfoo","description":"Test your prompts, agents, and RAGs. Red teaming, pentesting, and vulnerability scanning for LLMs. Compare performance of GPT, Claude, Gemini, Llama, and more. Simple declarative configs with command line and CI/CD integration.","topics":["llm","prompt-engineering","prompts","llmops","prompt-testing","testing","rag","evaluation","evaluation-framework","llm-eval"],"created_at":"2023-04-28T15:48:49Z","pushed_at":"2024-09-13T05:50:11Z","stargazers_count":4154,"language":"TypeScript"},{"full_name":"Giskard-AI/giskard","description":"üê¢ Open-Source Evaluation & Testing for ML models & LLMs","topics":["mlops","ml-validation","ml-testing","ai-testing","ai-safety","ml-safety","llmops","ethical-artificial-intelligence","responsible-ai","fairness-ai"],"created_at":"2022-03-06T21:45:37Z","pushed_at":"2024-09-13T10:35:13Z","stargazers_count":3911,"language":"Shell"},{"full_name":"tensorchord/envd","description":"üèïÔ∏è Reproducible development environment","topics":["developer-tools","development-environment","docker","buildkit","hacktoberfest","llmops","mlops","mlops-workflow","model-serving"],"created_at":"2022-04-11T09:04:19Z","pushed_at":"2024-09-09T02:42:51Z","stargazers_count":1949,"language":"Makefile"},{"full_name":"agenta-ai/agenta","description":"The all-in-one LLM developer platform: prompt management, evaluation, human feedback, and deployment all in one place.","topics":["langchain","llmops","large-language-models","llm","llm-tools","llms","prompt-engineering","prompt-management","llama-index","llm-evaluation"],"created_at":"2023-04-26T09:54:28Z","pushed_at":"2024-09-13T08:42:04Z","stargazers_count":1163,"language":"Dockerfile"},{"full_name":"mani-kantap/llm-inference-solutions","description":"A collection of all available inference solutions for the LLMs","topics":["llm-inference","llm-serving","llmops"],"created_at":"2023-07-23T20:39:23Z","pushed_at":"2024-08-31T15:43:44Z","stargazers_count":65,"language":"unknown"}],"frecuent_topics":{"llmops":11,"llm":6,"mlops":4,"llm-serving":4,"model-serving":3}}