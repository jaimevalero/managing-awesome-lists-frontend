{"category_type":"topic","category_name":"llmops","repos_data":[{"full_name":"langfuse/langfuse","description":"ü™¢ Open source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets. Integrates with OpenTelemetry, Langchain, OpenAI SDK, LiteLLM, and more. üçäYC W23 ","topics":["analytics","llm","llmops","large-language-models","openai","self-hosted","ycombinator","monitoring","observability","open-source"],"created_at":"2023-05-18T17:47:09Z","pushed_at":"2026-01-16T22:54:32Z","stargazers_count":20774,"language":"JavaScript"},{"full_name":"comet-ml/opik","description":"Debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards.","topics":["open-source","langchain","openai","playground","prompt-engineering","llama-index","llm","llm-evaluation","llm-observability","llmops"],"created_at":"2023-05-10T12:57:13Z","pushed_at":"2026-01-19T09:05:03Z","stargazers_count":17341,"language":"Shell"},{"full_name":"Portkey-AI/gateway","description":"A blazing fast AI Gateway with integrated guardrails. Route to 200+ LLMs, 50+ AI Guardrails with 1 fast & friendly API.","topics":["gateway","generative-ai","llmops","llms","ai-gateway","langchain","openai","hacktoberfest","llm","llm-gateway"],"created_at":"2023-08-23T11:52:47Z","pushed_at":"2026-01-12T18:01:35Z","stargazers_count":10324,"language":"TypeScript"},{"full_name":"typpo/promptfoo","description":"Test your prompts, agents, and RAGs. AI Red teaming, pentesting, and vulnerability scanning for LLMs. Compare performance of GPT, Claude, Gemini, Llama, and more. Simple declarative configs with command line and CI/CD integration.","topics":["llm","prompt-engineering","prompts","llmops","prompt-testing","testing","rag","evaluation","evaluation-framework","llm-eval"],"created_at":"2023-04-28T15:48:49Z","pushed_at":"2026-01-19T07:05:35Z","stargazers_count":9985,"language":"TypeScript"},{"full_name":"promptfoo/promptfoo","description":"Test your prompts, agents, and RAGs. AI Red teaming, pentesting, and vulnerability scanning for LLMs. Compare performance of GPT, Claude, Gemini, Llama, and more. Simple declarative configs with command line and CI/CD integration.","topics":["llm","prompt-engineering","prompts","llmops","prompt-testing","testing","rag","evaluation","evaluation-framework","llm-eval"],"created_at":"2023-04-28T15:48:49Z","pushed_at":"2026-01-19T07:05:35Z","stargazers_count":9985,"language":"TypeScript"},{"full_name":"bentoml/BentoML","description":"The easiest way to serve AI apps and models - Build Model Inference APIs, Job queues, LLM apps, Multi-model pipelines, and more!","topics":["model-serving","mlops","llmops","generative-ai","llm-inference","model-inference-service","inference-platform","deep-learning","llm-serving","machine-learning"],"created_at":"2019-04-02T01:39:27Z","pushed_at":"2026-02-08T03:01:26Z","stargazers_count":8415,"language":"Python"},{"full_name":"tensorchord/envd","description":"üèïÔ∏è Reproducible development environment for humans and agents","topics":["developer-tools","development-environment","docker","buildkit","hacktoberfest","llmops","mlops","mlops-workflow","model-serving","agent"],"created_at":"2022-04-11T09:04:19Z","pushed_at":"2026-01-07T11:20:49Z","stargazers_count":2178,"language":"Makefile"},{"full_name":"dagworks-inc/burr","description":"Build applications that make decisions (chatbots, agents, simulations, etc...). Monitor, trace, persist, and execute on your own infrastructure.","topics":["burr","dags","graphs","llmops","llms","mlops","persistent-data-structure","state-machine","state-management","visibility"],"created_at":"2024-01-29T23:27:07Z","pushed_at":"2026-01-18T11:46:05Z","stargazers_count":1886,"language":"Python"},{"full_name":"duaraghav8/MCPJungle","description":"Self-hosted MCP Gateway and Registry for AI agents","topics":["ai-agents","model-context-protocol","infrastructure","mcp-gateway","mcp","mcp-server","self-hosted","llmops","mcp-registry"],"created_at":"2025-05-15T12:31:06Z","pushed_at":"2026-01-19T05:45:21Z","stargazers_count":813,"language":"Go"},{"full_name":"langfuse/mcp-server-langfuse","description":"Model Context Protocol (MCP) Server for Langfuse Prompt Management. This server allows you to access and manage your Langfuse prompts through the Model Context Protocol.","topics":["langfuse","llm","llmops","mcp","model-context-protocol","prompt-management","prompting"],"created_at":"2025-02-15T11:58:06Z","pushed_at":"2025-02-16T14:03:25Z","stargazers_count":153,"language":"TypeScript"},{"full_name":"zenml-io/mcp-zenml","description":"MCP server to connect an MCP client (Cursor, Claude Desktop etc) with your ZenML MLOps and LLMOps pipelines","topics":["llmops","mcp","mcp-server","mlops"],"created_at":"2025-02-22T15:49:15Z","pushed_at":"2026-01-16T09:45:41Z","stargazers_count":40,"language":"Python"}],"frecuent_topics":{"llmops":11,"llm":6,"mlops":4,"openai":3,"prompt-engineering":3}}