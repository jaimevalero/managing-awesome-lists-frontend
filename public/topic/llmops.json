{"category_type":"topic","category_name":"llmops","repos_data":[{"full_name":"vllm-project/vllm","description":"A high-throughput and memory-efficient inference and serving engine for LLMs","topics":["gpt","llm","pytorch","llmops","mlops","model-serving","transformer","llm-serving","inference","llama"],"created_at":"2023-02-09T11:23:20Z","pushed_at":"2024-05-02T04:29:55Z","stargazers_count":18791,"language":"Python"},{"full_name":"bentoml/OpenLLM","description":"Run any open-source LLMs, such as Llama 2, Mistral, as OpenAI compatible API endpoint in the cloud.","topics":["llm","llmops","model-inference","falcon","fine-tuning","stablelm","llm-serving","llama","mpt","vicuna"],"created_at":"2023-04-19T00:27:52Z","pushed_at":"2024-04-30T19:06:47Z","stargazers_count":8822,"language":"Python"},{"full_name":"langfuse/langfuse","description":"ü™¢ Open source LLM engineering platform: Observability, metrics, evals, prompt management, playground, datasets. Integrates with LlamaIndex, Langchain, OpenAI SDK, LiteLLM, and more. üçäYC W23 ","topics":["analytics","llm","llmops","gpt","large-language-models","openai","self-hosted","ycombinator","monitoring","observability"],"created_at":"2023-05-18T17:47:09Z","pushed_at":"2024-05-02T05:02:01Z","stargazers_count":3515,"language":"JavaScript"},{"full_name":"typpo/promptfoo","description":"Test your prompts, models, and RAGs. Catch regressions and improve prompt quality. LLM evals for OpenAI, Azure, Anthropic, Gemini, Mistral, Llama, Bedrock, Ollama, and other local & private models with CI/CD integration.","topics":["llm","prompt-engineering","prompts","llmops","prompt-testing","testing","rag","evaluation","evaluation-framework","llm-eval"],"created_at":"2023-04-28T15:48:49Z","pushed_at":"2024-05-02T05:42:35Z","stargazers_count":2757,"language":"TypeScript"},{"full_name":"tensorchord/envd","description":"üèïÔ∏è Reproducible development environment","topics":["developer-tools","development-environment","docker","buildkit","hacktoberfest","llmops","mlops","mlops-workflow","model-serving"],"created_at":"2022-04-11T09:04:19Z","pushed_at":"2024-04-29T02:42:55Z","stargazers_count":1919,"language":"Makefile"},{"full_name":"agenta-ai/agenta","description":"The all-in-one LLM developer platform: prompt management, evaluation, human feedback, and deployment all in one place.","topics":["langchain","llmops","large-language-models","llm","llm-tools","llms","prompt-engineering","prompt-management","llama-index","llm-evaluation"],"created_at":"2023-04-26T09:54:28Z","pushed_at":"2024-05-01T18:39:45Z","stargazers_count":837,"language":"Dockerfile"}],"frecuent_topics":{"llmops":6,"llm":5,"gpt":2,"mlops":2,"model-serving":2}}