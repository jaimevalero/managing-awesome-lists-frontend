{"category_type":"topic","category_name":"vicuna","repos_data":[{"full_name":"bentoml/OpenLLM","description":"Run any open-source LLMs, such as Llama 2, Mistral, as OpenAI compatible API endpoint in the cloud.","topics":["llm","llmops","model-inference","falcon","fine-tuning","stablelm","llm-serving","llama","mpt","vicuna"],"created_at":"2023-04-19T00:27:52Z","pushed_at":"2024-04-30T19:06:47Z","stargazers_count":8822,"language":"Python"},{"full_name":"Facico/Chinese-Vicuna","description":"Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model —— 一个中文低资源的llama+lora方案，结构参考alpaca","topics":["llama","alpaca","chinese","vicuna"],"created_at":"2023-03-23T01:54:50Z","pushed_at":"2024-03-07T09:47:53Z","stargazers_count":4134,"language":"Python"}],"frecuent_topics":{"llama":2,"vicuna":2,"llm":1,"llmops":1,"model-inference":1}}