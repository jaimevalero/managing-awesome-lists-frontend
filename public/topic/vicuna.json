{"category_type":"topic","category_name":"vicuna","repos_data":[{"full_name":"bentoml/OpenLLM","description":"Run any open-source LLMs, such as DeepSeek and Llama, as OpenAI compatible API endpoint in the cloud.","topics":["llm","llmops","model-inference","fine-tuning","llm-serving","llama","vicuna","bentoml","llama2","llm-inference"],"created_at":"2023-04-19T00:27:52Z","pushed_at":"2025-12-15T16:55:53Z","stargazers_count":12006,"language":"Python"}],"frecuent_topics":{"llm":1,"llmops":1,"model-inference":1,"fine-tuning":1,"llm-serving":1}}